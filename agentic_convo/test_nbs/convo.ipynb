{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb410ca-8eae-4379-9a5d-fab53aa91aa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agent_prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magent_prompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m customer_sys_prompt, support_agent_sys_prompt\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversableAgent\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'agent_prompts'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from agent_prompts import customer_sys_prompt, support_agent_sys_prompt\n",
    "from autogen import ConversableAgent\n",
    "from dotenv import load_dotenv\n",
    "from itertools import islice\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7187a15f-4bee-4139-966f-43a5b17abe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"price\": [0.000150, 0.000600],\n",
    "            \"cache_seed\": None,\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7273392f-2600-4ef6-a77c-f10922c1a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(\n",
    "    name: str,\n",
    "    sys_prompt: str,\n",
    "    human_input_mode: str,\n",
    "    termination_msg: str | None = None,\n",
    "):\n",
    "    return ConversableAgent(\n",
    "        name=name,\n",
    "        system_message=sys_prompt,\n",
    "        is_termination_msg=lambda msg: termination_msg in msg[\"content\"]\n",
    "        if termination_msg\n",
    "        else None,\n",
    "        human_input_mode=human_input_mode,\n",
    "        llm_config=llm_config,\n",
    "        silent=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bbeb11-fae7-47db-8d32-fc634261ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_queries(queries: dict[str, str | list[str]]):\n",
    "    guidelines = queries[\"guidelines\"]\n",
    "    f = open(\"convo.txt\", \"a\")\n",
    "    for i, query in enumerate(queries[\"customer_queries\"]):\n",
    "        if i == 3:\n",
    "            break\n",
    "        customer_agent = create_agent(\n",
    "            \"Customer\",\n",
    "            customer_sys_prompt.format(guidelines=guidelines),\n",
    "            \"NEVER\",\n",
    "            \"RESOLVED\",\n",
    "        )\n",
    "        support_agent = create_agent(\n",
    "            \"Support_Agent\", support_agent_sys_prompt, \"NEVER\", \"RESOLVED\"\n",
    "        )\n",
    "        chat_result = customer_agent.initiate_chat(support_agent, message=query)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a8a2d2-f8a3-4905-8832-c21e2f542b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../query_gen/queries.jsonl\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         queries = json.loads(line)\n",
    "#         process_queries(queries)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4342794b-69c7-4658-8187-db2055c91173",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_batch(queries: list[str], out_file, guidelines: str):\n",
    "    \"\"\"Processes a batch of queries.\"\"\"\n",
    "    for j, query in enumerate(queries[\"customer_queries\"]):\n",
    "        customer_agent = create_agent(\n",
    "            \"Customer\",\n",
    "            customer_sys_prompt.format(guidelines=guidelines),\n",
    "            \"NEVER\",\n",
    "            \"RESOLVED\",\n",
    "        )\n",
    "        support_agent = create_agent(\n",
    "            \"Support_Agent\", support_agent_sys_prompt, \"NEVER\", \"RESOLVED\"\n",
    "        )\n",
    "\n",
    "        # remove number at the start if present\n",
    "        query = re.sub(r\"^\\d+\\.\\s*\", \"\", query)\n",
    "        chat_result = await customer_agent.a_initiate_chat(support_agent, message=query)\n",
    "        out_json = {\n",
    "            \"title\": queries[\"title\"], \n",
    "            \"tone\": queries[\"tone\"],\n",
    "            \"style\": queries[\"style\"],\n",
    "            \"conversation\": chat_result.chat_history,\n",
    "            \"length\": len(chat_result.chat_history),\n",
    "            \"status\": \"UNRESOLVED\" if \"UNRESOLVED\" in chat_result.chat_history[-1][\"content\"]\\\n",
    "                      else \"RESOLVED\"\n",
    "        }\n",
    "        json.dump(out_json, out_file, ensure_ascii=False)\n",
    "        out_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64cb873d-8409-4038-ac68-0d4d88f58cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_query_file(inp_file_str: str, out_file_str: str, batch_sz: int = 3):\n",
    "    inp_file = open(inp_file_str, 'r')\n",
    "    out_file = open(out_file_str, 'r')\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "        query_set = list(islice(inp_file, batch_sz))\n",
    "        if not batch:\n",
    "            print(f\"Finished generation for file: {inp_file_str}\")\n",
    "            break\n",
    "\n",
    "        print(f\"Processing query_set {i}.\")\n",
    "        tasks = [\n",
    "            process_batch(\n",
    "                queries=json.loads(queries)[\"customer_queries\"],\n",
    "                out_file=out_file,\n",
    "                guidelines=open(f\"/home/suchitg/amazon_help/leafdirs/{queries[\"title\"]}/t.txt\", \"r\").read()\n",
    "            )\n",
    "            for queries in query_set\n",
    "        ]\n",
    "        await asyncio.gather(*tasks)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9e0e22b-90f4-481c-9aed-87e507c38596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 11-18 12:25:20] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:21] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:24] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:24] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:28] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:28] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:31] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:31] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:38] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:38] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:47] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:25:47] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:26:00] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 11-18 12:26:00] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "def process_query_file(inp_file_str: str, out_file_str: str, batch_sz: int = 3):\n",
    "    inp_file = open(inp_file_str, 'r')\n",
    "    out_file = open(out_file_str, 'r')\n",
    "\n",
    "    \n",
    "    for i, line in enumerate(inp_file):\n",
    "        queries = json.loads(line)\n",
    "        guidelines = open(f\"/home/suchitg/amazon_help/leafdirs/{queries['title']}/t.txt\", \"r\").read()\n",
    "        for j, query in enumerate(queries[\"customer_queries\"]):\n",
    "            customer_agent = create_agent(\n",
    "                \"Customer\",\n",
    "                customer_sys_prompt.format(guidelines=guidelines),\n",
    "                \"NEVER\",\n",
    "                \"RESOLVED\",\n",
    "            )\n",
    "            support_agent = create_agent(\n",
    "                \"Support_Agent\", support_agent_sys_prompt, \"NEVER\", \"RESOLVED\"\n",
    "            )\n",
    "            query = re.sub(r\"^\\d+\\.\\s*\", \"\", query)\n",
    "            chat_result = await customer_agent.a_initiate_chat(support_agent, message=query)\n",
    "            out_json = {\n",
    "                \"title\": queries[\"title\"], \n",
    "                \"tone\": queries[\"tone\"],\n",
    "                \"style\": queries[\"style\"],\n",
    "                \"conversation\": chat_result.chat_history,\n",
    "                \"length\": len(chat_result.chat_history),\n",
    "                \"status\": \"UNRESOLVED\" if \"UNRESOLVED\" in chat_result.chat_history[-1][\"content\"]\\\n",
    "                          else \"RESOLVED\"\n",
    "            }\n",
    "            json.dump(out_json, out_file, ensure_ascii=False)\n",
    "            out_file.write(\"\\n\")\n",
    "            # open(\"./convo.jsonl\", 'a').write('\\n')\n",
    "        break\n",
    "        #     if j == 5:\n",
    "        #         break\n",
    "        # if i == 2:\n",
    "        #     break\n",
    "    \n",
    "    inp_file.close()\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a089ad-be0a-4069-bbc2-981ce6d936f7",
   "metadata": {},
   "source": [
    "- send file to main function for processing\n",
    "- each file has many _batches_ of queries\n",
    "    - each batch has a bunch of customer queries\n",
    "- process 1 file at a time\n",
    "- the \"bunch\" of queries in each batch can be processed asynchronously by autogen native async functionality\n",
    "- TODO: process batches in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42feb0a4-7425-4ce3-bebb-560172a09fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.39613747596741\n"
     ]
    }
   ],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596df0e9-2dec-45ed-b2eb-87a5a80b26e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd42ca-6533-45e9-95ea-1f45e8a003ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "078e23bd-01d0-48ae-9bd5-1045fc952498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d951af-4622-47ab-9c88-95fb9247c02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE:  {'title': 'ShipppingSpeedAndCharges', 'tone': 'neutral', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "oo:  101\n",
      "oo:  101\n",
      "EE:  {'title': 'UnkownCharges', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'PriceMatching', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'PaymentIssues', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'InstantBankDiscounts', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'RequestAtoZGuaranteeRefund', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'CouponsFAQ', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'FAQAboutWarranty', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'ReportAnEmergencyIncident', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'ShipmentIsLate', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'DamagedDefectiveOrWrongProductFAQ', 'tone': 'cheerful', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'CancelItemsOrOrders', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "EE:  {'title': 'CancelItemsOrOrders', 'tone': 'annoyed', 'style': 'non_native', 'conversation': [], 'length': 0, 'status': 'ERROR', 'error': \"Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\"}\n",
      "oo:  101\n"
     ]
    }
   ],
   "source": [
    "r, u = 0, 0\n",
    "convo_len = 0\n",
    "length = 0\n",
    "len_stats = []\n",
    "i = 0\n",
    "err = 0\n",
    "for line in open(\"../conversation_data/non_native_convos.jsonl\", 'r'):\n",
    "    l = json.loads(line)\n",
    "    if l['length'] > 50:\n",
    "        print(\"oo: \", l['length'])\n",
    "    len_stats.append(l['length'])\n",
    "    convo_len += l['length']\n",
    "    length += 1\n",
    "    i += 1\n",
    "        \n",
    "    if l[\"status\"] == \"RESOLVED\":\n",
    "        r += 1\n",
    "    else:\n",
    "        u += 1\n",
    "\n",
    "    if l['status'] == \"ERROR\":\n",
    "        err += 1\n",
    "        print(\"EE: \", l)\n",
    "        \n",
    "\n",
    "    if l['length'] > 20:\n",
    "        temp =  l['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee878900-d3f7-4bc2-8c5f-905515d6b850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2583, 1316)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712310de-aacd-453a-ba30-5f24de6b3051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.094126699153628"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_len / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a9c813-8109-4129-a14c-99e4cf4516b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len_stats), max(len_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc26996-4426-43c5-997f-8bd36d7772bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07db3127-8541-41a5-a9b4-55909017ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(len_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142880b4-c8f4-42c3-8b5f-9cdc257ff48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.000e+00, 2.000e+00, 4.980e+02, 2.732e+03, 4.560e+02, 1.430e+02,\n",
       "        4.300e+01, 1.500e+01, 3.000e+00, 1.000e+00]),\n",
       " array([ 0. ,  2.3,  4.6,  6.9,  9.2, 11.5, 13.8, 16.1, 18.4, 20.7, 23. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(len_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a57233-af18-481c-b450-3eccf73c13dd",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- identify and remove convos with super-long lengths\n",
    "- look into errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4b49b-a9b6-43ca-ab76-6ee608ef431b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
